{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13aaa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e34ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_game_data(dir_path, game_id) -> None:\n",
    "    \"\"\"\n",
    "    Download data of a specific game into a particular dir path\n",
    "    :param dir_path: Path to the dir\n",
    "    :param game_id: Game id of the game that we want to download\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(dir_path, game_id+\".json\")\n",
    "    \n",
    "    # Return if file path already exists\n",
    "    if(os.path.exists(file_path)):\n",
    "            return\n",
    "        \n",
    "    try:\n",
    "        with urllib.request.urlopen(\"https://statsapi.web.nhl.com/api/v1/game/\" + game_id + \"/feed/live/\") as url:\n",
    "            data = json.load(url)\n",
    "            if \"messageNumber\" in data and \"message\" in data \\\n",
    "                and data[\"messageNumber\"] == 2 and data[\"message\"] == \"Game data couldn't be found\":\n",
    "                pass\n",
    "            else:\n",
    "                with open(file_path, 'w') as outfile:\n",
    "                    json.dump(data, outfile)\n",
    "    except HTTPError as he:\n",
    "        print(game_id)\n",
    "        print(he.reason)\n",
    "    except Exception:\n",
    "        print('game_id: '+str(game_id))\n",
    "        e_type, e_value, e_traceback = sys.exc_info()\n",
    "        print(e_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a27d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_raw_data(target_year, dir_path):\n",
    "    \"\"\"\n",
    "    Download data of all games in a specific year\n",
    "    :param target_year: The year that we want to get data\n",
    "    :param dir_path: Path to the directory we want to store data (not including year) \n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    # Common variables and processing\n",
    "    available_years = ['2016', '2017', '2018', '2019', '2020']\n",
    "    \n",
    "    if(target_year not in available_years):\n",
    "        print(\"Dataset does not contain the entered year\")\n",
    "        return\n",
    "        \n",
    "    # Declare dir path\n",
    "    regular_dir_path = os.path.join(dir_path, target_year, 'regular_games')\n",
    "    playoff_dir_path = os.path.join(dir_path, target_year, 'playoff_games')\n",
    "    \n",
    "    # Create dir if it does not exist\n",
    "    if not os.path.exists(regular_dir_path):\n",
    "        os.makedirs(regular_dir_path)\n",
    "    if not os.path.exists(playoff_dir_path):\n",
    "        os.makedirs(playoff_dir_path)\n",
    "    \n",
    "    # Download data of regular games\n",
    "    print(\"Starting download data for regular games of season \"+target_year)\n",
    "    \n",
    "    # Season 2016 has 1230 games, while the rest have 1271\n",
    "    ID_range = 1231 if (target_year=='2016') else 1271\n",
    "    \n",
    "    for ID in tqdm(range(1, ID_range)):\n",
    "        # Convert ID from integer to string\n",
    "        ID_str =  \"0\"*(4 - len(str(ID))) + str(ID)\n",
    "        regular_game_id = target_year+\"02\"+ID_str\n",
    "        \n",
    "        # Download data of each game\n",
    "        download_game_data(regular_dir_path, regular_game_id)\n",
    "    \n",
    "    # Download data of playoff games\n",
    "    print(\"Starting download data for playoff games of season \"+target_year)\n",
    "    \n",
    "    # There are 4 rounds in total\n",
    "    for round_number in tqdm(range(1, 5)):\n",
    "        # round 1 has 8 matchups, round 2 has 4 matchups and so on\n",
    "        number_of_matchups = int(2**(3-round_number))\n",
    "        for matchup_number in range(1, number_of_matchups+1):\n",
    "            # Each match up has 7 games in total\n",
    "            for game_number in range(1, 8):\n",
    "                playoff_game_id = target_year+\"030\"+str(round_number)+str(matchup_number)+str(game_number)\n",
    "                download_game_data(playoff_dir_path, playoff_game_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e51700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download data for regular games of season 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1270/1270 [06:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download data for playoff games of season 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "download_raw_data('2018', \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58b74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
